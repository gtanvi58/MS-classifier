{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTlv-iPxuZLt"
      },
      "source": [
        "This code performs a majority vote on the generated labels by the ensemble model and calculates the accuracy of the ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBkotIZRvY70"
      },
      "outputs": [],
      "source": [
        "# Upload the following files in the runtime:\n",
        "# val_dataset.csv\n",
        "# all label files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQIE4FH0YEY2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data from CSV file\n",
        "val_dataset = pd.read_csv('./val_dataset.csv')\n",
        "\n",
        "y_val = val_dataset['label'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the predicted labels generated by each model in the ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFHSDxBUWYs6"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# File path in the Colab runtime\n",
        "file_path_0 = '/content/generated_labels0.pkl'\n",
        "file_path_1 = '/content/generated_labels1.pkl'\n",
        "file_path_2 = '/content/generated_labels2.pkl'\n",
        "file_path_3 = '/content/generated_labels3.pkl'\n",
        "\n",
        "# Load the list from the file\n",
        "with open(file_path_0, 'rb') as file:\n",
        "    generated_labels0 = pickle.load(file)\n",
        "\n",
        "with open(file_path_1, 'rb') as file:\n",
        "    generated_labels1 = pickle.load(file)\n",
        "\n",
        "with open(file_path_2, 'rb') as file:\n",
        "    generated_labels2 = pickle.load(file)\n",
        "\n",
        "with open(file_path_3, 'rb') as file:\n",
        "    generated_labels3 = pickle.load(file)\n",
        "\n",
        "print(\"Labels extracted from the files\")\n",
        "print(generated_labels0)\n",
        "print(generated_labels1)\n",
        "print(generated_labels2)\n",
        "print(generated_labels3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate the performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXgnXplCXuBK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "all_predictions = [generated_labels0, generated_labels1, generated_labels2, generated_labels3]\n",
        "\n",
        "final_predicted_labels = []\n",
        "\n",
        "for predictions in zip(*all_predictions):\n",
        "    # Count the occurrences of each label in the current set of predictions\n",
        "    label_counts = Counter(predictions)\n",
        "\n",
        "    # Find the label with the highest count (majority vote)\n",
        "    majority_label = max(label_counts, key=label_counts.get)\n",
        "\n",
        "    # Append the majority voted label to the final predicted labels list\n",
        "    final_predicted_labels.append(majority_label)\n",
        "\n",
        "\n",
        "# Convert generated_outputs to binary labels (0 or 1)\n",
        "final_predicted_labels = [1 if label == '1' else 0 for label in generated_labels]\n",
        "\n",
        "print(\"Predicted: \\n\", final_predicted_labels)\n",
        "\n",
        "# Convert y_val to binary labels (0 or 1)\n",
        "actual_labels = [1 if label == 1 else 0 for label in y_val]\n",
        "\n",
        "print(\"Actual: \\n\",actual_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(actual_labels, final_predicted_labels)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(actual_labels, final_predicted_labels)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(actual_labels, final_predicted_labels)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(actual_labels, final_predicted_labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
